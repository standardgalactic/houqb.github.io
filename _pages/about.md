---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Qibin Hou received his Ph.D. degree from Nankai University in 06/2019 under the supervision of Prof. Ming-Ming Cheng. From 08/2019 to 08/2021, I spent two wonderful years working with Dr. Jiashi Feng and Dr. Shuicheng Yan as a research fellow at National University of Singapore. Now, he is an associate professor at School of Computer Science, Nankai University, Tianjin, China. I am also with Nankai International Advanced Research Institute (Shenzhen Futian).
 <a href='https://scholar.google.com/citations?user=fF8OFV8AAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=Citation"></a>ã€‚

## Research Interestsï¼š

My research covers a range of `Computer Vision` and `Deep Learning`. To be specific, my research concentrates on building AI models to help agents better see and understand the complex world. 

Specific directions: `Semantic Segmentation` `Object Detection` `Foundation Models`

See my recent publications for more details.

<span class='anchor' id='-student'></span>

## For perspective students

If you are interested in the research topics in my group, welcome to drop an email. Note that before contacting me, you are supposed to have read <a href="https://mmcheng.net/recruit/" class="redlink">[this]</a> already.

We have several projects each year from the industry to ensure the applications of our research.

<span class='anchor' id='-news'></span>

+ Five papers accepted by CVPR'24
+ Three papers accepted by ICLR'24 and AAAI'24
+ Three papers accepted by ICCV'23 and CVPR'23
+ Top 2% of Scientists on Stanford List
+ Five papers published in T-PAMI'2023
 
<span class='anchor' id='-lwzl'></span>

## Selected Journal Publications ([Google Scholar](https://scholar.google.com/citations?user=fF8OFV8AAAAJ&hl=en))

#### "*" means authors contributed equally and "#" means corresponding author.

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Vision permutator: A permutable mlp-like architecture for visual recognition</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Zihang Jiang, Li Yuan, Ming-Ming Cheng, Shuicheng Yan, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2106.12368.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/VisionPermutator" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Volo: Vision outlooker for visual recognition</h4>   
  <sub><p style="line-height:15px"> Li Yuan*, <b>Qibin Hou</b>*, Zihang Jiang*, Jiashi Feng, Shuicheng Yan</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://ieeexplore.ieee.org/abstract/document/9888055">[Arxiv]</a> <a href="https://github.com/sail-sg/volo" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Localization distillation for object detection</h4>   
  <sub><p style="line-height:15px"> Zhaohui Zheng, Rongguang Ye, <b>Qibin Hou</b>#, Dongwei Ren, Ping Wang, Wangmeng Zuo, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2204.05957.pdf">[Arxiv]</a> <a href="https://github.com/HikariTJU/LD" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Deeply Supervised Salient Object Detection with Short Connections</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Ming-Ming Cheng, Xiaowei Hu, Ali Borji, Zhuowen Tu, Philip Torr</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2019</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2306.04300.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/DSS" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

## Selected Conference Publications ([Google Scholar](https://scholar.google.com/citations?user=fF8OFV8AAAAJ&hl=en))

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>CorrMatch: Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation</h4>   
  <sub><p style="line-height:15px"> Boyuan Sun, Yuqi Yang, Le Zhang, Ming-Ming Cheng, <b>Qibin Hou#</b></p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.pdf">[Arxiv]</a> <a href="https://github.com/BBBBchan/CorrMatch">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>CrossKD: Cross-Head Knowledge Distillation for Dense Object Detection</h4>   
  <sub><p style="line-height:15px"> Jiabao Wang*, Yuming Chen*, Zhaohui Zheng, Xiang Li, Ming-Ming Cheng, <b>Qibin Hou#</b></p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2306.11369.pdf">[Arxiv]</a> <a href="https://github.com/jbwang1997/CrossKD">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Dformer: Rethinking rgbd representation learning for semantic segmentation</h4>   
  <sub><p style="line-height:15px"> Bowen Yin, Xuying Zhang, Zhongyu Li, Li Liu, Ming-Ming Cheng, <b>Qibin Hou#</b> </p> 
  <p style="line-height:15px">International Conference on Learning Representations (ICLR), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2309.09668.pdf">[Arxiv]</a> <a href="https://github.com/VCIP-RGBD/DFormer">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>SRFormer: Permuted Self-Attention for Single Image Super-Resolution</h4>   
  <sub><p style="line-height:15px"> Yupeng Zhou, Zhen Li, Chun-Le Guo, Song Bai, Ming-Ming Cheng, <b>Qibin Hou#</b> </p> 
  <p style="line-height:15px">IEEE International Conference on Computer Vision (ICCV), 2023</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf">[Arxiv]</a> <a href="https://github.com/HVision-NKU/SRFormer">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Localization Distillation for Dense Object Detection</h4>   
  <sub><p style="line-height:15px"> Zhaohui Zheng*, Rongguang Ye*, Ping Wang, Dongwei Ren, Wangmeng Zuo, <b>Qibin Hou#</b>, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.pdf">[Arxiv]</a> <a href="https://github.com/HikariTJU/LD">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Coordinate attention for efficient mobile network design</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Daquan Zhou, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/
CoordAttention">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Li Zhang, Ming-Ming Cheng, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2003.13328.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/SPNet">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>A Simple Pooling-Based Design for Real-Time Salient Object Detection</h4>   
  <sub><p style="line-height:15px"> Jiang-Jiang Liu*, <b>Qibin Hou*</b>, Ming-Ming Cheng, Jiashi Feng, Jianmin Jiang</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019</p>   
  <p style="line-height:15px"> <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.pdf">[Arxiv]</a> <a href="https://github.com/backseason/PoolNet">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Self-Earsing Networks for Integral Object Attention</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Peng-Tao Jiang, Yunchao Wei, Ming-Ming Cheng </p> 
  <p style="line-height:15px">Advances in Neural Information Processing Systems (NeurIPS), 2018</p>   
  <p style="line-height:15px"> <a href="https://papers.nips.cc/paper/7336-self-erasing-network-for-integral-object-attention.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/SeeNet">[Code]</a></p>   
  </sub>
</blockquote>



<span class='anchor' id='-ryjx'></span>

# ğŸ… è£èª‰å¥–é¡¹
- *2015.11* è·å¾— ç¬¬åå››å±Šâ€œæŒ‘æˆ˜æ¯â€å…¨å›½å¤§å­¦ç”Ÿè¯¾å¤–å­¦æœ¯ç§‘æŠ€ä½œå“ç«èµ› `ä¸€ç­‰å¥–`  
- *2015.06* è·å¾— ç¬¬åä¸‰å±Šâ€œæŒ‘æˆ˜æ¯â€å››å·å¤§å­¦ç”Ÿè¯¾å¤–å­¦æœ¯ç§‘æŠ€ä½œå“ç«èµ› `ä¸€ç­‰å¥–` [[æ–°é—»]](https://www.sc.gov.cn/10462/10778/10876/2015/7/1/10341562.shtml)  
- *2014.12* è·å¾— ç¬¬å››å±Šå…¨å›½å¤§å­¦ç”Ÿå·¥ç¨‹è®­ç»ƒç»¼åˆèƒ½åŠ›ç«èµ›ï¼ˆå››å·èµ›åŒºï¼‰ `ä¸€ç­‰å¥–`  

<span class='anchor' id='-xshy'></span>

# ğŸ›ï¸ å­¦æœ¯ä¼šè®®
- *2021.10*, å…¨å›½ç”µç£æ— æŸæ£€æµ‹æŠ€æœ¯ç ”è®¨ä¼š æš¨ ä¸­å›½æœºæ¢°å·¥ç¨‹å­¦ä¼šæ— æŸæ£€æµ‹åˆ†ä¼šç”µç£ä¸“ä¸šæŠ€æœ¯å¤§ä¼šç¬¬åä¸€å±Šç¬¬å››æ¬¡å…¨ä½“ä¼šè®®, é™•è¥¿è¥¿å®‰, å—é‚€æŠ¥å‘Š
- *2019.09*, ç¬¬åä¹å±Šå›½é™…åº”ç”¨ç”µç£å­¦ä¸åŠ›å­¦ä¼šè®® (ISEM 2019), æ±Ÿè‹å—äº¬, æµ·æŠ¥
- *2017.10*, ç¬¬å…­å±Šä¸­å›½å›½é™…ç®¡é“ä¼šè®® (CIPC 2017), æ²³åŒ—å»ŠåŠ

<span class='anchor' id='-gzsx'></span>

# ğŸ’» å·¥ä½œå®ä¹ 
- *2018.05 - 2020.02*, é‡åº†é•¿æ±Ÿè½´æ‰¿è‚¡ä»½æœ‰é™å…¬å¸, é‡åº†
- *2020.11.25 - 2020.12.02*, æ¹–åŒ—æ–°å†¶é’¢æœ‰é™å…¬å¸, æ¹–åŒ—é»„çŸ³
- *2017.6 - 2021.1*, åˆ¶é€ è£…å¤‡æ•°å­—åŒ–å›½å®¶å·¥ç¨‹ç ”ç©¶ä¸­å¿ƒ, æ¹–åŒ—æ­¦æ±‰
