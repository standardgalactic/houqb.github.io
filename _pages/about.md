---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Qibin Hou received his Ph.D. degree from Nankai University in 06/2019 under the supervision of Prof. Ming-Ming Cheng. From 08/2019 to 08/2021, I spent two wonderful years working with Dr. Jiashi Feng and Dr. Shuicheng Yan as a research fellow at National University of Singapore. Now, he is an associate professor at School of Computer Science, Nankai University, Tianjin, China. I am also with Nankai International Advanced Research Institute (Shenzhen Futian).
 <a href='https://scholar.google.com/citations?user=fF8OFV8AAAAJ'><img src="https://img.shields.io/endpoint?logo=Google%20Scholar&url=https%3A%2F%2Fcdn.jsdelivr.net%2Fgh%2Fhouqb%2Fhouqb.github.io@google-scholar-stats%2Fgs_data_shieldsio.json&labelColor=f1f1f1&color=aff&style=flat&label=citations"></a>

## Research Interests：

My research covers a range of `Computer Vision` and `Deep Learning`. To be specific, my research concentrates on building AI models to help agents better see and understand the complex world. 

Specific directions: `Vision Foundation Models` `Visual Scene Understanding` `Visual Content Generation`

See my recent publications for more details.

<span class='anchor' id='-fs'></span>

## For prospective students

If you are interested in the research topics in my group, welcome to drop an email. Note that before contacting me, you are supposed to have read <a href="https://mmcheng.net/recruit/" class="redlink">[this]</a> already.

We have several projects each year from the industry to ensure the applications of our research.

<span class='anchor' id='-news'></span>

## News

+ Two papers accepted by T-PAMI'2024
+ I am among the list of Highly Cited Chinese Researchers of 2023
+ Six papers accepted by CVPR'24 and ECCV'24
+ Three papers accepted by ICLR'24 and ICML'24
+ Three papers accepted by ICCV'23 and CVPR'23
+ Top 2% of Scientists on Stanford List for multiple times
+ Five papers published in T-PAMI'2023

<span class='anchor' id='-group'></span>

## Group

#### Ph.D. Students

+ Zhaohui Zheng (Co-supervise with Ming-Ming Cheng)
+ Jiabao Wang (Co-supervise with Ming-Ming Cheng)
+ Boyuan Sun (Co-supervise with Prof. Xiuli Shao)
+ Hao Shao
+ Bowen Yin
+ [Xuying Zhang](https://zhangxuying1004.github.io/) (Co-supervise with Ming-Ming Cheng)

#### Master Students

+ Yupeng Zhou
+ Yuqi Yang (Co-supervise with Prof. Ming-Ming Cheng)
+ Yuming Chen (Co-supervise with Prof. Xiuli Shao)
 
<span class='anchor' id='-pub'></span>

## Preprint

#### "*" means authors contributed equally and "#" means corresponding author.

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>StoryDiffusion: Consistent Self-Attention for Long-Range Image and Video Generation</h4>   
  <sub><p style="line-height:15px"> Yupeng Zhou, Daquan Zhou#, Ming-Ming Cheng, Jiashi Feng, <b>Qibin Hou</b># </p>
  <p style="line-height:15px">Arxiv, 2024</p>   
  <iframe 
src="https://ghbtns.com/github-btn.html?user=HVision-NKU&repo=StoryDiffusion&type=star&count=true&size=small" frameborder="0"
scrolling="0"
width="170"
height="20"
title="GitHub">
</iframe>
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2405.01434">[Arxiv]</a> <a href="https://storydiffusion.github.io/" class="redlink">[Project]</a> <a href="https://github.com/HVision-NKU/StoryDiffusion" class="redlink">[Code]</a> </p>   
  </sub>
</blockquote>



## Selected Journal Publications ([Google Scholar](https://scholar.google.com/citations?user=fF8OFV8AAAAJ&hl=en))



<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Conv2former: A simple transformer-style convnet for visual recognition</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Cheng-Ze Lu, Ming-Ming Cheng#, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2211.11943">[Arxiv]</a> <a href="https://github.com/HVision-NKU/Conv2Former" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Zone evaluation: Revealing spatial bias in object detection</h4>   
  <sub><p style="line-height:15px">Zhaohui Zheng, Yuming Chen, <b>Qibin Hou</b>#, Xiang Li, Ping Wang, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2310.13215">[Arxiv]</a> <a href="https://github.com/Zzh-tju/ZoneEval" class="redlink">[Code]</a> <a href="https://zhuanlan.zhihu.com/p/602113455" class="redlink">[知乎]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Vision permutator: A permutable mlp-like architecture for visual recognition</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Zihang Jiang, Li Yuan, Ming-Ming Cheng, Shuicheng Yan, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2106.12368.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/VisionPermutator" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Volo: Vision outlooker for visual recognition</h4>   
  <sub><p style="line-height:15px"> Li Yuan*, <b>Qibin Hou</b>*, Zihang Jiang*, Jiashi Feng, Shuicheng Yan</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://ieeexplore.ieee.org/abstract/document/9888055">[Arxiv]</a> <a href="https://github.com/sail-sg/volo" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Localization distillation for object detection</h4>   
  <sub><p style="line-height:15px"> Zhaohui Zheng, Rongguang Ye, <b>Qibin Hou</b>#, Dongwei Ren, Ping Wang, Wangmeng Zuo, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2204.05957.pdf">[Arxiv]</a> <a href="https://github.com/HikariTJU/LD" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Contrastive masked autoencoders are stronger vision learners</h4>   
  <sub><p style="line-height:15px"> Zhicheng Huang, Xiaojie Jin, Chengze Lu, <b>Qibin Hou</b>, Ming-Ming Cheng, Dongmei Fu, Xiaohui Shen, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2023</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2207.13532">[Arxiv]</a> <a href="https://github.com/ZhichengHuang/CMAE" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>



<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Online Attention Accumulation for Weakly Supervised Semantic Segmentation</h4>   
  <sub><p style="line-height:15px"> Peng-Tao Jiang, Ling-Hao Han, <b>Qibin Hou</b>, Ming-Ming Cheng, Yunchao Wei</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2022</p>   
  <p style="line-height:15px"> <a href="https://www.researchgate.net/profile/Peng-Tao-Jiang/publication/352810988_Online_Attention_Accumulation_for_Weakly_Supervised_Semantic_Segmentation/links/62844cd5a5268672baf91a65/Online-Attention-Accumulation-for-Weakly-Supervised-Semantic-Segmentation.pdf">[Arxiv]</a> <a href="https://mmcheng.net/oaa/" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Deeply Supervised Salient Object Detection with Short Connections</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Ming-Ming Cheng, Xiaowei Hu, Ali Borji, Zhuowen Tu, Philip Torr</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017</p> 
  <p style="line-height:15px">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2019</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2306.04300.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/DSS" class="redlink">[Code]</a></p>   
  </sub>
</blockquote>

## Selected Conference Publications ([Google Scholar](https://scholar.google.com/citations?user=fF8OFV8AAAAJ&hl=en))



<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Cascade-CLIP: Cascaded Vision-Language Embeddings Alignment for Zero-Shot Semantic Segmentation</h4>   
  <sub><p style="line-height:15px"> Yunheng Li, ZhongYu Li, Quansheng Zeng, <b>Qibin Hou#</b>, Ming-Ming Cheng</p> 
  <p style="line-height:15px">International Conference on Machine Learning (ICML), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2406.00670">[Arxiv]</a> <a href="https://github.com/HVision-NKU/Cascade-CLIP">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>CorrMatch: Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation</h4>   
  <sub><p style="line-height:15px"> Boyuan Sun, Yuqi Yang, Le Zhang, Ming-Ming Cheng, <b>Qibin Hou#</b></p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.pdf">[Arxiv]</a> <a href="https://github.com/BBBBchan/CorrMatch">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>CrossKD: Cross-Head Knowledge Distillation for Dense Object Detection</h4>   
  <sub><p style="line-height:15px"> Jiabao Wang*, Yuming Chen*, Zhaohui Zheng, Xiang Li, Ming-Ming Cheng, <b>Qibin Hou#</b></p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2306.11369.pdf">[Arxiv]</a> <a href="https://github.com/jbwang1997/CrossKD">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Multi-Task Dense Prediction via Mixture of Low-Rank Experts</h4>   
  <sub><p style="line-height:15px"> Yuqi Yang, Peng-Tao Jiang, <b>Qibin Hou#</b>, Hao Zhang, Jinwei Chen, Bo Li</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Yang_Multi-Task_Dense_Prediction_via_Mixture_of_Low-Rank_Experts_CVPR_2024_paper.pdf">[Arxiv]</a> <a href="https://github.com/YuqiYang213/MLoRE">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>TeMO: Towards Text-Driven 3D Stylization for Multi-Object Meshes</h4>   
  <sub><p style="line-height:15px">Xuying Zhang, Bo-Wen Yin, Yuming Chen, Zheng Lin, Yunheng Li, <b>Qibin Hou#</b>, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_TeMO_Towards_Text-Driven_3D_Stylization_for_Multi-Object_Meshes_CVPR_2024_paper.pdf">[Arxiv]</a> <a href="https://github.com/zhangxuying1004/TeMO">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Dformer: Rethinking rgbd representation learning for semantic segmentation</h4>   
  <sub><p style="line-height:15px"> Bowen Yin, Xuying Zhang, Zhongyu Li, Li Liu, Ming-Ming Cheng, <b>Qibin Hou#</b> </p> 
  <p style="line-height:15px">International Conference on Learning Representations (ICLR), 2024</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2309.09668.pdf">[Arxiv]</a> <a href="https://github.com/VCIP-RGBD/DFormer">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>SRFormer: Permuted Self-Attention for Single Image Super-Resolution</h4>   
  <sub><p style="line-height:15px"> Yupeng Zhou, Zhen Li, Chun-Le Guo, Song Bai, Ming-Ming Cheng, <b>Qibin Hou#</b> </p> 
  <p style="line-height:15px">IEEE International Conference on Computer Vision (ICCV), 2023</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf">[Arxiv]</a> <a href="https://github.com/HVision-NKU/SRFormer">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Localization Distillation for Dense Object Detection</h4>   
  <sub><p style="line-height:15px"> Zhaohui Zheng*, Rongguang Ye*, Ping Wang, Dongwei Ren, Wangmeng Zuo, <b>Qibin Hou#</b>, Ming-Ming Cheng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2022</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Localization_Distillation_for_Dense_Object_Detection_CVPR_2022_paper.pdf">[Arxiv]</a> <a href="https://github.com/HikariTJU/LD">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Coordinate attention for efficient mobile network design</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Daquan Zhou, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2021</p>   
  <p style="line-height:15px"> <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/
CoordAttention">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Li Zhang, Ming-Ming Cheng, Jiashi Feng</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020</p>   
  <p style="line-height:15px"> <a href="https://arxiv.org/pdf/2003.13328.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/SPNet">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>A Simple Pooling-Based Design for Real-Time Salient Object Detection</h4>   
  <sub><p style="line-height:15px"> Jiang-Jiang Liu*, <b>Qibin Hou*</b>, Ming-Ming Cheng, Jiashi Feng, Jianmin Jiang</p> 
  <p style="line-height:15px">IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019</p>   
  <p style="line-height:15px"> <a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.pdf">[Arxiv]</a> <a href="https://github.com/backseason/PoolNet">[Code]</a></p>   
  </sub>
</blockquote>

<blockquote style="color: black;  border-width: 8px; border-color: orange">   
  <h4>Self-Earsing Networks for Integral Object Attention</h4>   
  <sub><p style="line-height:15px"> <b>Qibin Hou</b>, Peng-Tao Jiang, Yunchao Wei, Ming-Ming Cheng </p> 
  <p style="line-height:15px">Advances in Neural Information Processing Systems (NeurIPS), 2018</p>   
  <p style="line-height:15px"> <a href="https://papers.nips.cc/paper/7336-self-erasing-network-for-integral-object-attention.pdf">[Arxiv]</a> <a href="https://github.com/Andrew-Qibin/SeeNet">[Code]</a></p>   
  </sub>
</blockquote>

<span class='anchor' id='-services'></span>

## Academic Services

+ VALSE 2022 Expo Chair
+ VALSE 2023 Expo Chair
+ Reviewers for TPAMI/TIP/CVPR/ICCV/NeurIPS/ICML/ICLR etc.

<span class='anchor' id='-awards'></span>

## Honors and Awards

+ First prize in natural science, Ministry of Education, 2022.
+ Second prize in nature science, CAAI, 2020.


